output_dir: "./new-results"
model_name_or_path: "meta-llama/Llama-2-7b-chat-hf"
data_path: "/home/cmin/LLM-Interpretation-Playground/benchmarks/malicious_instruct/Jailbreak_LLM-main/data/MaliciousInstruct.txt"
mode: "train"
batchsize: 1
accumulation_steps: 100
search: True
add_kl: False
schedule_type: "constant"
warmup: 0
lr: 3e-3
max_steps: 5
weight_decay: 0.02
do_eval: True
eval_log_strategy: "steps"
eval_log_step: 1
peft_type: "llama-adapter"
adapter_len: 20
target_layers: 32
adapter_layers: 32
training_set_name: happy_search_100_greedy
eval_set_name: happy_search_10_eval_heldout
attribute: "happy"
run_name: "emo-100-9e-4-100bz-100steps-02warmup"
push_name: "lora-test"